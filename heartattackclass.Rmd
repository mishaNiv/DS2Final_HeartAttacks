## General libraries

```{r}
library(caret)
library(corrplot)
```


## Read in data

```{r}
heart <- read.csv("heart.csv")

heart
```

slp: the slope of the peak exercise ST segment (2=upsloping, 1=flat;0=downsloping)
thall: a blood disorder called thalassemia. 2-normal 1-fixed defect 3-reversible defect
old peak: the ST depression induced by exercise relative to rest

## EDA

```{r}
summary(heart)
```

Everything has values, there are a number of binaries

Correlation plot :)

```{r}
corrplot(cor(heart), method = "shade",
         title = "Correlation of Heart Data",
         col = colorRampPalette(c("white","lightsalmon","brown2"))(100),
         tl.pos = "l", 
         mar = c(2, 1, 3, 1),
         tl.cex = 0.75,
         tl.col = "darkred"
         ) 
```


## Split intro train/test sets

```{r}
# set seed
set.seed(904)

# create row index; 80% split
tIndex <- sample(1:nrow(heart), 0.8*nrow(heart))

# use index to split intro train/test
trainD <- heart[tIndex, ]
testD <- heart[-tIndex, ]
```

# Random Forest classification

## Load random forest package

```{r}
library(randomForest)
```

### Build classification model

```{r}
heart.rf <- randomForest(as.factor(output) ~ ., data=trainD, importance=TRUE, proximity=TRUE)
```

```{r}
confusionMatrix(data=predict(heart.rf, testD), reference=as.factor(testD$output))
```

Accuracy value of 0.9016.

mtry, ntrees

```{r}
mvar <- c(1:13)
nvar <- seq(25, 1000, 25)
bestmod <- heart.rf
bestval <- 0

for (val in mvar) {
  mvar1 <- mvar[val]
  
  for (val in nvar) {
    newheart <- randomForest(as.factor(output) ~ ., data=trainD, importance=TRUE, proximity=TRUE, mtry=mvar1, ntrees=nvar)
    conf <- confusionMatrix(data=predict(newheart, testD), reference=as.factor(testD$output))

    if(conf$overall['Accuracy'] > bestval) {
      bestmod <- newheart
      bestval <- conf$overall['Accuracy']
    }
    
  }
}


```


```{r}
bestmod
bestval

```

```{r}
confusionMatrix(data=predict(bestmod, testD), reference=as.factor(testD$output))
```


# SVM Classification

### Libraries 

```{r}
library(e1071)
```

### Build model

```{r}
heart.svm = svm(formula = output ~ ., data = trainD, type = 'C-classification', kernel = 'linear')
```

### Find accuracy

```{r}
confusionMatrix(data=predict(heart.svm, testD), reference=as.factor(testD$output))
```

This is already at 91.8%. That's pretty good.

```{r}
heart.svm = svm(formula = output ~ ., data = trainD, type = 'C-classification', kernel = 'linear')
confusionMatrix(data=predict(heart.svm, testD), reference=as.factor(testD$output))
```


```{r}
gvar <- c(-5:5)
evar <- seq(0, 1, 0.05)
bestmod <- heart.svm
bestval <- 0

for (val in gvar) {
  gvar1 <- gvar[val]
  
  for (val in evar) {
    newheart <- svm(formula = output ~ ., data = trainD, type = 'C-classification', kernel = 'linear', epsilon=evar, gamma=10^gvar1)
    conf <- confusionMatrix(data=predict(newheart, testD), reference=as.factor(testD$output))

    if(conf$overall['Accuracy'] > bestval) {
      bestmod <- newheart
      bestval <- conf$overall['Accuracy']
    }
    
  }
}


```


```{r}
bestmod
bestval

```

This is fractionally better than the original svm model. The random forest model seems to be better.

SVM was certainly much quicker to reach a similar accuracy, but RF still has the higher accuracy.